# Natural Language Explanation of Logical Rules in Knowledge Graphs

We explored using the OpenAI GPT-3.5 Turbo model to generate natural language explanations of logical rules. Specifically, we focus on rules discovered by AMIE using the benchmark dataset FB15k-237. 
We conducted a human evaluation generated by GPT, based on criteria such as correctness, clarity, and hallucination. 
Our findings based on the evaluation results demonstrate a promising direction for leveraging LLMs to generate explanations for logical rules.
The rules and evaluation metrics can be adapted and further extended to become a benchmark for evaluating natural language explanations of logical rules.

All our scripts and data are available in this repository. Our annotation results are available at `data/aggregated_annotations.xlsx`. 



